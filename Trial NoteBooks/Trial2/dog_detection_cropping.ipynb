{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not run unless new environment is created\n",
    "#%pip install torch==1.13.0\n",
    "#%pip install opencv-python\n",
    "#%pip install torchvision==0.14.0\n",
    "#%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version:  1.13.0\n",
      "torchvision version:  0.14.0\n",
      "cv2 version:  4.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "print('torch version: ', torch.__version__)\n",
    "print('torchvision version: ', torchvision.__version__)\n",
    "\n",
    "import cv2\n",
    "print('cv2 version: ', cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print torch version\n",
    "print(torch.__version__)\n",
    "#print opencv version\n",
    "print(cv2.__version__)\n",
    "#print torchvision version  \n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/david/anaconda3/envs/python3_9dis/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/david/anaconda3/envs/python3_9dis/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE:  IMPORT_PIC(PATH)    OUTPUT: IMG, COPY\n",
    "\n",
    "def import_pic(path):\n",
    "    img = cv2.imread(path)\n",
    "    copy = img.copy()\n",
    "    return img, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE:  TO_TENSOR(IMG)  OUTPUT: IMAGE_TENSOR\n",
    "\n",
    "def to_tensor(img):\n",
    "    image_tensor = F.to_tensor(img)\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE:  MAKE_PREDICTION(IMAGE_TENSOR, MODEL)    OUTPUT: PREDICTION\n",
    "\n",
    "def make_prediction(image_tensor, model):\n",
    "    prediction = model([image_tensor])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE:  BOUNDING_OBJECTS(PREDICTION)    OUTPUT: BOXES, LABELS, MASKS\n",
    "\n",
    "def bounding_objects(prediction):\n",
    "    boxes = prediction[0]['boxes']\n",
    "    labels = prediction[0]['labels']\n",
    "    masks = prediction[0]['masks']\n",
    "    return boxes, labels, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE:  APPLY(IMAGE, BOXES, LABELS, MASKS)  OUTPUT: IMAGE\n",
    "\n",
    "def apply(image, boxes, labels, masks):\n",
    "    for i in range(len(boxes)):\n",
    "        if labels[i] == 18:\n",
    "            box = boxes[i].detach().numpy()\n",
    "            mask = masks[i, 0].detach().numpy()\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            mask = mask.astype(image.dtype)\n",
    "\n",
    "            image = cv2.rectangle(image, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "            image = cv2.addWeighted(image, 0.5, mask, 0.5, 0)\n",
    "\n",
    "#    plt.figure(figsize=(20, 20))\n",
    "#    plt.imshow(image)\n",
    "#    plt.axis('off')\n",
    "#    plt.show()\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE: FIND_LARGEST_BOX(BOXES)  OUTPUT: LARGEST_BOX_COORD\n",
    "\n",
    "def find_largest_box(boxes):\n",
    "    largest_box = 0\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i].detach().numpy()\n",
    "        if (box[2]-box[0])*(box[3]-box[1]) > largest_box:\n",
    "            largest_box = (box[2]-box[0])*(box[3]-box[1])\n",
    "            largest_box_coord = box\n",
    "    return largest_box_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE: CROP(IMG, BOX_COORD, SIZE) OUTPUT: CROP_IMG\n",
    "\n",
    "def crop(img, box_coord, size):\n",
    "    v_size = box_coord[3] - box_coord[1]\n",
    "    h_size = box_coord[2] - box_coord[0]\n",
    "\n",
    "    assert v_size < size, (\"dog object larger than cropping size vertically\", v_size, ' > ', size)\n",
    "    assert h_size < size,(\"dog object is larger than cropping size horizontally\", h_size , ' > ' , size)\n",
    "\n",
    "    v_diff = size - v_size\n",
    "    h_diff = size - h_size\n",
    "\n",
    "    half_vdiff = v_diff/2\n",
    "    half_hdiff = h_diff/2\n",
    "\n",
    "    new_coord0 = box_coord[0] - half_hdiff\n",
    "    new_coord1 = box_coord[1] - half_vdiff\n",
    "    new_coord2 = box_coord[2] + half_hdiff\n",
    "    new_coord3 = box_coord[3] + half_vdiff\n",
    "    \n",
    "    if new_coord0 < 0:\n",
    "        new_coord0 = 0\n",
    "        new_coord2 = size\n",
    "\n",
    "    if new_coord1 < 0:\n",
    "        new_coord1 = 0\n",
    "        new_coord3 = size\n",
    "\n",
    "    if new_coord2 > img.shape[1]:\n",
    "        new_coord0 = img.shape[1] - size\n",
    "        new_coord2 = img.shape[1]\n",
    "\n",
    "    if new_coord3 > img.shape[0]:\n",
    "        new_coord1 = img.shape[0] - size\n",
    "        new_coord3 = img.shape[0]\n",
    "\n",
    "    crop_img = img[int(new_coord1) : int(new_coord3),int(new_coord0) : int(new_coord2)]\n",
    "    return crop_img\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   PROCEDURE: EXPORT(IMG, NAME, EP)    OUTPUT: BOOLEAN\n",
    "\n",
    "def export(img, name, ep):\n",
    "    if not os.path.exists(ep):\n",
    "        os.makedirs(ep)\n",
    "\n",
    "    path = ep + '/' + name + '.jpg'\n",
    "    cv2.imwrite(path, img)\n",
    "    #check if image was sucessfully written\n",
    "    if os.path.isfile(path):\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        \n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PROCEDURE: PIPELINE(MODEL, IP, NAME, EP, SIZE)    OUTPUT: BOOLEAN\n",
    "\n",
    "def pipeline(model, ip, name, ep, size=500):\n",
    "    img, copy = import_pic(ip)\n",
    "    image_tensor = to_tensor(img)\n",
    "    prediction = make_prediction(image_tensor, model)\n",
    "    boxes, labels, masks = bounding_objects(prediction)\n",
    "    applied_img = apply(copy, boxes, labels, masks)\n",
    "    largest = find_largest_box(boxes)\n",
    "    cropped = crop(img, largest, size)\n",
    "    exported = export(cropped, name, ep)\n",
    "\n",
    "    \n",
    "    #plt.imshow(cropped)\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "\n",
    "    if exported == True:\n",
    "        print('Cropped image successfully exported as :', name, '.jpg \\n ~~to the folder: ', ep)\n",
    "        return True\n",
    "    else:\n",
    "        print('Export failed, please try again')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PROCEDURE: ITER_PIP(MODEL, IP, EP, END, START, COUNTER_START)    OUTPUT: NONE\n",
    "\n",
    "def iter_pip(model, ip, ep, end, start= 0, counter_start=0):\n",
    "    i = start\n",
    "    counter = counter_start\n",
    "    \n",
    "    while i < end:\n",
    "        try:\n",
    "            img_path = ip + '/' + str(i) + '.jpg'\n",
    "            pipeline(model, img_path, str(counter), ep)\n",
    "        \n",
    "        except AssertionError as e:\n",
    "            print(e)\n",
    "            print('Image skipped')\n",
    "            pass\n",
    "        counter += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped image successfully exported as : 0 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 1 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 2 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 3 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 4 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 5 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 6 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 7 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 8 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 9 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 10 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 11 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 12 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 13 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 14 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 15 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 16 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 17 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n"
     ]
    }
   ],
   "source": [
    "iter_pip(model,\n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/frames/laying', \n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying', \n",
    "        18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped image successfully exported as : 18 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 19 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 20 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 21 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 22 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 23 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 24 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 25 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 26 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 27 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 28 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 29 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 30 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 31 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 32 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 33 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 34 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n",
      "Cropped image successfully exported as : 35 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying\n"
     ]
    }
   ],
   "source": [
    "iter_pip(model,\n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/trial1_pup1/frames/laying', \n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/laying', \n",
    "        18,\n",
    "        counter_start = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dog object is larger than cropping size horizontally', 1550.3015, ' > ', 1000)\n",
      "Image skipped\n",
      "('dog object is larger than cropping size horizontally', 1492.9512, ' > ', 1000)\n",
      "Image skipped\n",
      "('dog object is larger than cropping size horizontally', 1216.1204, ' > ', 1000)\n",
      "Image skipped\n",
      "Cropped image successfully exported as : 3 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/sitting\n",
      "('dog object is larger than cropping size horizontally', 1048.3164, ' > ', 1000)\n",
      "Image skipped\n",
      "Cropped image successfully exported as : 5 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/sitting\n",
      "Cropped image successfully exported as : 6 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/sitting\n",
      "('dog object is larger than cropping size horizontally', 1591.3654, ' > ', 1000)\n",
      "Image skipped\n",
      "('dog object is larger than cropping size horizontally', 1410.7374, ' > ', 1000)\n",
      "Image skipped\n",
      "Cropped image successfully exported as : 9 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/sitting\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m iter_pip(model,\n\u001b[1;32m      2\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39m/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/frames/sitting\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      3\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39m/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/sitting\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m         \u001b[39m43\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m, in \u001b[0;36miter_pip\u001b[0;34m(model, ip, ep, end, start, counter_start)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     img_path \u001b[39m=\u001b[39m ip \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     pipeline(model, img_path, \u001b[39mstr\u001b[39;49m(counter), ep)\n\u001b[1;32m     12\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(e)\n",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(model, ip, name, ep, size)\u001b[0m\n\u001b[1;32m      8\u001b[0m applied_img \u001b[39m=\u001b[39m apply(copy, boxes, labels, masks)\n\u001b[1;32m      9\u001b[0m largest \u001b[39m=\u001b[39m find_largest_box(boxes)\n\u001b[0;32m---> 10\u001b[0m cropped \u001b[39m=\u001b[39m crop(img, largest, size)\n\u001b[1;32m     11\u001b[0m exported \u001b[39m=\u001b[39m export(cropped, name, ep)\n\u001b[1;32m     14\u001b[0m \u001b[39m#plt.imshow(cropped)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#plt.axis('off')\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#plt.show()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mcrop\u001b[0;34m(img, box_coord, size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcrop\u001b[39m(img, box_coord, size):\n\u001b[0;32m----> 4\u001b[0m     v_size \u001b[39m=\u001b[39m box_coord[\u001b[39m3\u001b[39;49m] \u001b[39m-\u001b[39m box_coord[\u001b[39m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m     h_size \u001b[39m=\u001b[39m box_coord[\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m box_coord[\u001b[39m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[39massert\u001b[39;00m v_size \u001b[39m<\u001b[39m size, (\u001b[39m\"\u001b[39m\u001b[39mdog object larger than cropping size vertically\u001b[39m\u001b[39m\"\u001b[39m, v_size, \u001b[39m'\u001b[39m\u001b[39m > \u001b[39m\u001b[39m'\u001b[39m, size)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "iter_pip(model,\n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/frames/sitting', \n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/sitting', \n",
    "        43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped image successfully exported as : 0 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 1 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 2 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 3 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 4 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 5 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 6 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 7 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 8 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 9 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 10 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 11 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 12 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 13 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "('dog object larger than cropping size vertically', 560.7639, ' > ', 500)\n",
      "Image skipped\n",
      "('dog object larger than cropping size vertically', 603.1084, ' > ', 500)\n",
      "Image skipped\n",
      "('dog object larger than cropping size vertically', 607.2472, ' > ', 500)\n",
      "Image skipped\n",
      "('dog object larger than cropping size vertically', 599.05054, ' > ', 500)\n",
      "Image skipped\n",
      "Cropped image successfully exported as : 18 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 19 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 20 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 21 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 22 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 23 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 24 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 25 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 26 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 27 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 28 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 29 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 30 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 31 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 32 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 33 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 34 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 35 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 36 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 37 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 38 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 39 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 40 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 41 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 42 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 43 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 44 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 45 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 46 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 47 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 48 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 49 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 50 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 51 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 52 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 53 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 54 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 55 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 56 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 57 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 58 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 59 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 60 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 61 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 62 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 63 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 64 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 65 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 66 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 67 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 68 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 69 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 70 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 71 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 72 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "('dog object larger than cropping size vertically', 557.6258, ' > ', 500)\n",
      "Image skipped\n",
      "Cropped image successfully exported as : 74 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 75 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 76 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "('dog object larger than cropping size vertically', 501.95074, ' > ', 500)\n",
      "Image skipped\n",
      "Cropped image successfully exported as : 78 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 79 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "('dog object larger than cropping size vertically', 547.7307, ' > ', 500)\n",
      "Image skipped\n"
     ]
    }
   ],
   "source": [
    "iter_pip(model,\n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/frames/standing', \n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing', \n",
    "        81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped image successfully exported as : 78 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 79 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 80 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 81 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 82 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 83 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 84 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 85 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 86 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 87 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 88 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 89 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 90 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 91 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 92 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 93 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 94 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 95 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 96 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 97 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 98 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 99 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 100 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 101 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 102 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 103 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 104 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 105 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 106 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 107 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 108 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 109 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 110 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 111 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 112 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 113 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 114 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n",
      "Cropped image successfully exported as : 115 .jpg \n",
      " ~~to the folder:  /Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing\n"
     ]
    }
   ],
   "source": [
    "iter_pip(model,\n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/trial1_pup1/frames/standing', \n",
    "        '/Users/david/Desktop/shelter_dogs_research/Data/Trail2_env1/cropped/standing', \n",
    "        38,\n",
    "        counter_start = 78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
